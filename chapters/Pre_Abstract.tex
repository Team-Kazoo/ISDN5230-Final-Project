\begin{abstract}

The transformation of human vocal input into expressive instrumental sounds represents a fundamental challenge at the intersection of signal processing, human-computer interaction, and neural audio synthesis. We present Mambo Whistle, a comprehensive real-time vocal synthesis framework that achieves professional-grade audio transformation through two complementary deployment modalities: a browser-based implementation enabling universal accessibility, and an embedded hardware implementation on the Raspberry Pi 5 platform delivering superior latency characteristics for demanding musical applications.

Our system introduces a novel hybrid architecture that strategically combines classical digital signal processing algorithms with modern neural sequence generation through Google Magenta's MusicRNN. The browser-based implementation operates entirely within standard web browsers using the AudioWorklet API, achieving 50--60ms end-to-end latency without requiring software installation. The embedded implementation, deployed on the Raspberry Pi 5's quad-core ARM Cortex-A76 processor with PREEMPT\_RT real-time Linux kernel, reduces latency to 18--24ms through native C++ execution, FFTW3 with ARM NEON SIMD optimization, and direct ALSA audio interface access.

The Raspberry Pi 5 deployment demonstrates that sophisticated audio synthesis previously requiring dedicated hardware can now be achieved on a \$80 single-board computer. The BCM2712 system-on-chip provides sufficient computational headroom for real-time YIN pitch detection, FFT spectral analysis, and TensorFlow Lite neural inference while maintaining stable thermal operation with active cooling. Extensive evaluation demonstrates system robustness through 235 comprehensive automated tests, 72-hour continuous operation stability testing, and detailed performance profiling confirming real-time capability across both deployment configurations.

The proposed framework advances the state-of-the-art in accessible music technology by demonstrating that low-latency vocal-to-instrument synthesis with AI-powered harmonic accompaniment can be delivered both through standard web browsers for universal accessibility and through embedded hardware for professional performance applications, thereby democratizing access to expressive musical instruments for users worldwide regardless of their technical resources or expertise.

\end{abstract}
