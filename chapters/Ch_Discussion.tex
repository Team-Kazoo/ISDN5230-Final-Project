\chapter{Discussion and Future Work}\label{chap:discussion}

\section{Limitations and Constraints}\label{sec:limitations}

Despite the substantial capabilities demonstrated by Mambo Whistle, several limitations constrain current system applicability and suggest directions for continued development. Forthright acknowledgment of these limitations contextualizes our contributions and identifies opportunities for impactful future research.

The achieved latency of 50--60 milliseconds, while representing a significant advancement for browser-based audio processing, remains perceptible to trained musicians performing rapid passages. Research on musical performance timing indicates that performers can perceive delays as small as 20--30 milliseconds when they conflict with established sensorimotor expectations, suggesting that further latency reduction would benefit professional applications. The theoretical minimum latency achievable through our current architecture approaches 5 milliseconds, limited by buffer accumulation requirements for accurate low-frequency pitch detection. Achieving this theoretical minimum would require optimization of buffer management strategies and potentially WebAssembly acceleration of compute-intensive algorithms.

The monophonic limitation inherent in YIN-based pitch detection restricts system applicability to single-voice input, precluding processing of polyphonic vocal techniques such as overtone singing or multiple simultaneous performers. While polyphonic pitch detection algorithms exist, they impose substantially higher computational costs and reduced accuracy compared to monophonic approaches, presenting challenging tradeoffs for real-time browser execution. The current monophonic focus reflects a pragmatic scope limitation appropriate for the target application of voice-controlled instrumental synthesis.

Neural model deployment introduces first-use latency as model weights download from cloud storage, typically requiring 2--3 seconds on broadband connections but potentially much longer on constrained networks. This initialization latency may impact user experience, particularly for users who expect immediate functionality upon page load. Progressive loading strategies or model caching through Service Workers could mitigate this limitation in future implementations.

Browser implementation variability introduces uncertainty regarding performance characteristics across deployment targets. Despite substantial standardization progress, browser vendors retain implementation flexibility that produces observable differences in latency, computational efficiency, and API behavior. Our extensive compatibility testing characterizes current browser behavior, but ongoing browser development may introduce regressions or improvements that alter system performance.

\section{Future Research Directions}\label{sec:future}

The foundation established by Mambo Whistle enables several promising research directions that could substantially extend system capabilities and broaden applicability. We outline these directions with attention to technical feasibility and potential impact.

Integration of neural pitch detection through lightweight models such as quantized CREPE variants could improve robustness in acoustically challenging environments including background noise and room reverberation. Recent work on model compression demonstrates that pitch detection networks can be quantized to achieve approximately 2 milliseconds inference time on modern CPUs, potentially compatible with real-time requirements. The architectural challenge lies in managing the inference latency contribution without substantially increasing end-to-end latency, potentially through speculative execution or confidence-based fallback to classical detection.

Migration to audio-domain neural synthesis through browser-compatible implementations of RAVE or DDSP would dramatically improve timbral quality and enable capabilities including timbre transfer and voice conversion. RAVE achieves 25x real-time performance on CPU, suggesting feasibility of browser deployment through TensorFlow.js or WebAssembly compilation. The primary challenges involve managing model size for reasonable download times and optimizing inference scheduling to maintain real-time audio generation without dropouts.

WebAssembly acceleration of compute-intensive algorithms could reduce processing time by 2--5x compared to JavaScript execution, enabling smaller buffer sizes and correspondingly lower latency. The Emscripten toolchain provides mature compilation from C++ to WebAssembly, enabling porting of optimized native implementations. The architectural challenge involves managing data transfer between JavaScript audio contexts and WebAssembly memory without introducing serialization overhead that negates computational savings.

Embedded hardware deployment through porting to platforms such as NVIDIA Jetson or Raspberry Pi 5 could achieve sub-10-millisecond latency suitable for professional musical applications while enabling standalone operation without dependency on browser environments. The modular architecture facilitating this transition would require reimplementation of the audio I/O layer for native audio APIs while preserving the algorithmic core with minimal modification.

Collaborative musical interaction through WebRTC integration could enable real-time ensemble performance over internet connections, with latency compensation algorithms maintaining musical synchronization despite network delays. This direction would extend system applicability from individual practice and performance to distributed musical collaboration, addressing the growing interest in remote music-making catalyzed by recent global circumstances.

\section{Broader Impact}\label{sec:impact}

The demonstrated feasibility of professional-grade audio synthesis within browser environments carries implications extending beyond the immediate application domain of voice-controlled instruments. These broader impacts merit consideration as they inform assessment of contribution significance and suggest additional application directions.

Music education stands to benefit substantially from zero-installation tools that eliminate the IT support overhead currently impeding deployment of music technology in schools. Teachers could direct students to web URLs providing immediate access to expressive instruments without software installation, permission requests, or compatibility concerns. This accessibility particularly benefits under-resourced educational settings where dedicated music technology budgets are unavailable.

Accessibility for musicians with motor impairments represents an important application direction, as voice-based control provides an alternative input modality for individuals unable to operate traditional instruments requiring manual dexterity. While voice control does not replicate the full expressive range of traditional instruments, it may enable musical participation previously foreclosed by physical limitations.

Privacy preservation through client-side processing addresses growing societal concern regarding audio surveillance and data collection. Unlike cloud-based voice processing services that necessarily transmit audio to remote servers, our architecture ensures that sensitive vocal data never leaves the user's device. This guarantee proves particularly valuable for applications involving children, where data protection regulations impose stringent requirements, and for users in jurisdictions with strong privacy expectations.

Research acceleration through browser-based deployment enables rapid prototyping and evaluation of audio algorithms with immediate access to realistic input through built-in microphones. Researchers can share working demonstrations through URLs rather than requiring evaluators to configure development environments, potentially accelerating the research feedback cycle and broadening participation in audio technology research.
